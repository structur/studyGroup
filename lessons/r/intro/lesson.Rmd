---
title: "Introduction to R"
author: "Luke Johnston"
date: "May 26, 2016"
output: md_document
---

 - **Authors**: Luke W. Johnston
 - **Research field**: Nutritional Sciences (epidemiology)
 - **Lesson topic**: Intro to R and data wrangling
 - **Lesson content URL**: <https://github.com/UofTCoders/studyGroup/tree/gh-pages/lessons/r/intro>
 - **Lesson video stream**: <https://www.youtube.com/watch?v=pbG_3ZuNyx8>

This is a brief introduction to R, focussing on data wrangling using
`dplyr` and `tidyr` packages and generating reproducible documents
using `knitr` and `rmarkdown` packages.

You **don't need to read all of this** for the session.  It's more of
a **resource and reference**.

R is a statistical computing environment to analyze data and write
programs.  The strength of R comes from:

* It being developed by statisticians to do statistical analysis
* Its graphic capacities are top-quality
* It has excellent resources for creating reproducible documents.
* Its extensive and active community of users for doing statistical
  work:
    - R is the top tag in the
      [StackExchange CrossValidated site](https://stats.stackexchange.com/tags)
      for statistical questions
    - There are more than 6000 packages on
      [CRAN](https://cran.r-project.org/web/packages/) that stores all
      R packages (and installing these packages is straight-forward),
      from the obscure and cutting-edge statistical techniques to
      plotting to data wrangling.

I should mention a quick caveat.  While R is a general-purpose
programming language, it works a bit differently from other languages
such as Python (it was developed by statisticians after all!).  As
such, programming in R may not be as intuitive, powerful, or easy as
it may be in Python (though it can be done), especially if you come
from a computer science background.  If your work involves a lot of
programming, I would recommend Python as your main tool.  *However*,
it never hurts to learn more than one language, especially as R is
great for data analysis and plotting.

Ok, firstly, I've made this session with some assumptions (see the
[slides.html](../slides.html)) file.  Briefly I'm assuming you want to
use R for statistical analysis, plotting, and/or writing up reports.
I'm using R Markdown to show how to write up documents with R code and
since getting the data into an analyzable form is the hardest part of
an analysis, I'm using packages specific to that task.

While you can create functions in R, I won't be going over them.  A
great resource for R functions is
[this page from Hadley Wickham's 'Advanced R' book](http://adv-r.had.co.nz/Functions.html)

# R Markdown #

An `.Rmd` or [R Markdown](http://rmarkdown.rstudio.com/) file is a
[markdown](https://en.wikipedia.org/wiki/Markdown) file that contains
R code chunks that can be processed to output the results of the R
code into a generated `.md` file.  This is an incredible (and recent)
strength of using R, as this then allows you to create html, pdf, or
Word doc files from the `.md` file using the `rmarkdown` package
(which relies on [pandoc](https://pandoc.org)).

On the top of each `.Rmd` file is the
[YAML](https://en.wikipedia.org/wiki/YAML) front matter, which looks
like:

```
---
title: "Introduction to R"
author: "Luke Johnston"
date: "July 23, 2015"
output: 
  html_document: 
    highlight: tango
    number_sections: yes
    theme: readable
    toc: yes
    
---
```

Note the starting and ending `---` 'tags'.  This starts the YAML
block.

Markdown syntax for formatting is used in `.Rmd`.  Check out the
[R Markdown documentation](http://rmarkdown.rstudio.com/) for a quick
tutorial on the syntax.

# Import/export your data #

You'll need to import your data into R to analyze it.  I'm assuming
the data is already cleaned and ready for analysis.  If at any time
you need help with a command, use the `?` command, appended with the
command of interest (eg. `?write.csv`).  R comes with many internal
datasets that you can practice on.  The one I'm going to use is the
`swiss` dataset.

```{r importData}

write.csv(swiss, file = 'swiss.csv') # Export
ds <- read.csv('swiss.csv') # Import

```

# Viewing your data #

R has several very useful and easy tools for quickly viewing your
data.  `head()` shows the first few rows of a data.frame (a structure
for storing data that can include numbers, integers, factors, strings,
etc).  `names()` shows the column names.  `str()` shows the structure,
such as what the object is, and its contents.  `summary()` shows a
quick description of the summary statistics (means, median, frequency)
for each of your columns.  `class()` is like `str()` but only shows
the top level name of the object, so eg. while a data.frame contains
multiple columns that `str()` would show, `class()` would only show
that the object is a "data.frame".

```{r viewData}
head(ds)
names(ds)
str(ds)
summary(ds)
class(ds)
```

# Wrangling your data #

Data wrangling is a bit tedious in base R.  So I'm using two packages
designed to make this easier.  Load packages by using the `library()`
function.  `dplyr` comes with a `%>%` pipe function (via the
`magrittr` package), which works similar to how the Bash shell `|`
pipe works.  The command on the right-hand side takes the output from
the command on the left-hand side, just like how a plumbing pipe works
for water.

The four lines of code below using `tbl_df` are all the same.  The `.`
object represents the output from the pipe, but it doesn't have to be
used as using `%>%` implies also using `.`.  `tbl_df` makes the object
into a `tbl` class, making printing of the output nicer.

```{r wrangle}

library(dplyr)
tbl_df(ds)
ds %>% tbl_df()
ds %>% tbl_df
ds %>% tbl_df(.)

## Let's put it into a new object
ds2 <- tbl_df(ds)

```

Again, these next lines are the same. `select` does as it says: select
the column from the dataset.

```{r wrangleSelect}

select(ds2, Education, Catholic, Fertility)
ds2 %>% select(Education, Catholic, Fertility)
ds2 %>% select(., Education, Catholic, Fertility)

```

You can rename columns either using `rename` or `select` (the new name
is on the left hand side, so `newname = oldname`).  However, with the
`select` command, only that column gets selected, while `rename`
selects all columns.

```{r wrangleRename}
ds2 %>% rename(County = X)
ds2 %>% select(County = X)
```

You can subset the dataset using `filter`.  Note the double equal sign
`==` for testing if 'Examination' is equal to 15.  A single `=` is
used for something else (assigning things to objects).

```{r wrangleFilter}

filter(ds2, Catholic < 20, Examination == 15)
ds2 %>% filter(Catholic < 20, Examination == 15)
ds2 %>% filter(., Catholic < 20, Examination == 15)
## For string/factor variables
ds2 %>% filter(X == 'Aigle')

```

We can start chaining these commands together using the `%>%` command.
There is no limit to how long a chain can be.  `arrange`
sorts/orders/re-arranges the column Education in ascending
order. `mutate` creates a new column.

```{r wrangleChain}

ds2 %>%
  filter(Catholic > 20) %>%
  select(Education, Fertility) 
  
ds2 %>%
  filter(Catholic > 20) %>%
  select(County = X, Education, Fertility, Agriculture) %>%
  arrange(Education) %>%
  mutate(infertile = ifelse(Fertility < 50, 'yes', 'no'),
         testing = 'Yes' ## Create a testing column to show how mutate works.
         )

```

To get the data into a nicer and more analyable format, you can use
the `tidyr` package.  See what `gather` does in the code below.  Then
see what `spread` does.  Note that you can remove a column by having a
minus `-` sign in front of a variable when you use `select`.

```{r reorg}

library(tidyr)
## Compare this:
ds2 %>%
  select(-Infant.Mortality) %>%
  rename(County = X)

## With this:
ds2 %>%
  select(-Infant.Mortality) %>%
  rename(County = X) %>%
  gather(Measure, Value, -County)

## And back again:
ds2 %>%
  select(-Infant.Mortality) %>%
  rename(County = X) %>%
  gather(Measure, Value, -County) %>%
  spread(Measure, Value)

```

Combined with `dplyr`'s `group_by` and `summarise` you can quickly
summarise data or do further, more complicated analyses. `group_by`
makes it so further analyses or operations work on the groups.
`summarise` transforms the data to only contain the new variable(s)
created, in this case the mean.

```{r reorgChain}

ds2 %>%
  select(-X) %>%
  gather(Measure, Value) %>%
  group_by(Measure) %>%
  summarise(mean = mean(Value))

```

You can extend this to be created as a table in the generated `.md` or
`.html` file using the `kable` command (short for 'knitr table').

```{r table}

library(knitr)
ds2 %>%
  select(-X) %>%
  gather(Measure, Value) %>%
  group_by(Measure) %>%
  summarise(mean = mean(Value)) %>%
  kable()

```

# Generate this document #

Check out the documentation on
[`knitr`](https://yihui.name/knitr/options/) or
[R Markdown](http://rmarkdown.rstudio.com/authoring_rcodechunks.html)
for R code chunk options.  If you look at the raw `.Rmd` file for this
[document](../main.Rmd), you can see that the below code chunk uses
`eval = FALSE`, which tells knitr to not run this code chunk.

These two commands generate either a html or a md file.

```{r render, eval = FALSE}

## into html
library(rmarkdown)
render('lesson.Rmd') ## or can use rmarkdown::render('main.Rmd')

## into md
library(knitr)
knit('lesson.Rmd') ## or can use knitr::knit('main.Rmd')

```

# Challenge: Try this out for yourself! #

Make a table with the means of Agriculture, Examination, Education,
and Infant.Mortality for each category of Fertility (hint: convert it
into a factor by values >50 vs <50), when Catholic is less than 60
(hint, use `dplyr` commands + `gather`).  Have the Fertility groups as
two columns in the new table (hint, use `spread` + `kable`).

# Python-ized version (courtesy of [@QuLogic](https://github.com/QuLogic))

<script src="https://gist.github.com/QuLogic/c65772479f6101393fc3.js"></script>
